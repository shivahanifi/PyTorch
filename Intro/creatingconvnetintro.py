# -*- coding: utf-8 -*-
"""CreatingConvNetIntro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1IhqX0IFM7O-nSD50Rf3jYTple7-Zs71I

## Building a CNN

Here we are going to create a convolutinal neural network following the [source](https://pythonprogramming.net/convnet-model-deep-learning-neural-network-pytorch/). In the previous tutorial the data preprocessing step was discussed for which the code has been added.

## Unzip the data
"""

!unzip drive/MyDrive/Colab\ Notebooks/PetImages

"""## Preprocessing the data

You need to do it once. Set the `REBUILD_DATA` to `True` and run this block of code once, to preprocess the data, then set it to `False`.
"""

import os
import cv2
import numpy as np
from tqdm import tqdm


REBUILD_DATA = False # set to true to one once, then back to false unless you want to change something in your training data.

class DogsVSCats():
    IMG_SIZE = 50
    CATS = "PetImages/Cat"
    DOGS = "PetImages/Dog"
    TESTING = "PetImages/Testing"
    LABELS = {CATS: 0, DOGS: 1}
    training_data = []

    catcount = 0
    dogcount = 0

    def make_training_data(self):
        for label in self.LABELS:
            print(label)
            for f in tqdm(os.listdir(label)):
                if "jpg" in f:
                    try:
                        path = os.path.join(label, f)
                        img = cv2.imread(path, cv2.IMREAD_GRAYSCALE)
                        img = cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE))
                        self.training_data.append([np.array(img), np.eye(2)[self.LABELS[label]]])  # do something like print(np.eye(2)[1]), just makes one_hot 
                        #print(np.eye(2)[self.LABELS[label]])

                        if label == self.CATS:
                            self.catcount += 1
                        elif label == self.DOGS:
                            self.dogcount += 1

                    except Exception as e:
                        pass
                        #print(label, f, str(e))

        np.random.shuffle(self.training_data)
        np.save("training_data.npy", self.training_data)
        print('Cats:',dogsvcats.catcount)
        print('Dogs:',dogsvcats.dogcount)

if REBUILD_DATA:
    dogsvcats = DogsVSCats()
    dogsvcats.make_training_data()


training_data = np.load("training_data.npy", allow_pickle=True)
print(len(training_data))

"""## Importing Modules"""

import torch
import torch.nn as nn
import torch.nn.functional as F

"""# Building The Network
## Convolutional Layers

At first we create the class, and in that class we start to make our layers. The basics of the network would be the same as before with the difference that here we are using the convolutional layers. Our network will have 3 convolutional layers. 

- *super()*

  returns a temporary object of the superclass that allows us to access methods of the base class.
- *self.conv1= nn.Conv2d(1, 32 ,5)*

  Applies a 2D convolution over an input signal composed of several input planes. Here we are using 2D because our input is image. Torch has also 1 (sequential/ temporal type datasets) and 3 (for models or scans) dimension  layers but you can use as many dimensions in your conv layers as you want. (If it doesn't exist in torch you can code it yourself!)
  - 1 – Number of channels in the input image

  - 32 – Number of channels produced by the convolution

  - 5 – Size of the convolving kernel
  It is going to make a 5 by 5 kernel/ window as it rolls over our data to find features.

## Linear Layers

At some point this network would need some dense/linear layers,. at least one, to be the distribution of predictions.
The main issue when you go from convolutional layers to fully connected layers or linear layers is to find out the number of inputs. In `Keras` there is a function called `flatten` and it is used at this point, but here with PyTorch there is no cush a function.

  ### What TO Do Now?
 We are going to simply determine the actual shape of the flattened output after the first convolutional layers. The suggested way to do that is to actually pass frake data through the convolutional layers and multiply the dimensions given at the output.

- *x = torch.randn(50,50).view(-1,1,50,50)*

Creating some random data to pass through the convolutional layers and get the dimension of the output.

  - `1` is related to the input at the first convolutional layer. How many images we have, they all gona be in their tensor form (1,50,50) and the actual tensor that we pass through the neural network will have this exact shape.

## Forward Method








"""

class Net(nn.module):
    def __init__(self):
        super().__init__()
        self.conv1= nn.Conv2d(1, 32 ,5)
        self.conv2= nn.Conv2d(32, 64 ,5)
        self.conv3= nn.Conv2d(64, 128 ,5)

        x = torch.randn(50,50).view(-1,1,50,50) # Creating fake, random data
        self.convs(x) # passing the fake data through the convolutional layers
    def conv(self, x): # Forward method