# -*- coding: utf-8 -*-
"""DataIntro.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1LYSRIaCvF91Q_ZYg9jDIKKZ3_2D36wVl

## PyTorch tutorial- working with data

Find the related video [here](https://www.youtube.com/watch?v=i2yPxY2rOzs&list=PLQVvvaa0QuDdeMyHEYc0gxFpYwHY2Qfdh&index=2)
"""

import torch
import torchvision
from torchvision import transforms, datasets

"""Downloading the MNIST dataset."""

train = datasets.MNIST("", train=True, download=True, transform = transforms.Compose([transforms.ToTensor()]))
test = datasets.MNIST("", train=False, download=True, transform = transforms.Compose([transforms.ToTensor()]))

"""Creating the train and test dataset

We are loading the data we already have downloaded.
Specify the batch size that is how many at a time do we want to pass to our model.

"""

trainset = torch.utils.data.DataLoader(train, batch_size=10, shuffle=True)
testset= torch.utils.data.DataLoader(test, batch_size=10, shuffle=True)

"""Iterating over the data

- The result is the entire batch, i.e. 10 examples of handwritten digits and then 10 tensors of the actual output
"""

for data in trainset:
  print(data)
  break #we don't wanna run allover them

"""The output is a tensor object containing first, a tensor of tensors that is your images, and second, a tensor of tensors that are your labels. In order to reference the image belonging to the first label we use data[0][0] and to reference the first label we use data [1][0]."""

x,y = data[0][0], data[1][0]
print(y)

"""Visualizing the data
We need to change the shape of the image because PyTorch changes the shape and is in the form of for example (1*28*28) to be able to plot it we have to rashape it to a usual image shape which is (28*28)
"""

import matplotlib.pyplot as plt
plt.imshow(data[0][0].view(28,28))
plt.show()

"""Balancing
If our dataset is unbalanced i.e. for example 70% 3s amd 5% 1s, etc. The model will learn that the easiest way to decrease the loss is to predict 3 everytime. The model will get stuck because it would not find the way out of it. Thjerefor, you generally want your dataset to be as balanced as possible.
"""

#Checking whether the dataset is balanced
#using a counter
total = 0
counter_dict = {0:0, 1:0, 2:0, 3:0, 4:0, 5:0, 6:0, 7:0, 8:0, 9:0}

for data in trainset:
  Xs,ys = data
  for y in ys:
    counter_dict[int(y)] +=1
    total+=1
print(counter_dict)

"""As we iterate over all of our data, we add these counters, we can kind of see where we are in terms of how many samples for each number that we have.

The result shows that how many samples we have for each number.
"""

#Percentage of the distiributions
for i in counter_dict:
  print(f"{i}: {counter_dict[i]/total*100}")

"""It shows that the data is balanced."""