# -*- coding: utf-8 -*-
"""IntroConvnet.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1SfYqmZma5Q9U6xP4IzvCWRYOCBLp_P9f

## Convolutional Neural Network Introduction
For this tutorial the following [source](https://pythonprogramming.net/convolutional-neural-networks-deep-learning-neural-network-pytorch/) have been followed.
Typically we mix different layers such as convolutional layers, fully connected layers etc. to build our network. Traditionally Convnets were used for image tasks. However, recently they outperform the recurrent neural networks in terms of sequential types of data.

### How does Convnet work?

Typically you pass the image to the network in its form and you don't have to flatten the image like we did in the fully connected layers. A convolutional neural network accepts 2D input and also can accept 3D inputs.

In case of 2D inputs, which are the most used ones, a 2D image is actually a 2D array of pixels and we apply a convolution on it. Which means passing a window, called kernel, over the image and its goal is to locate features of an image. First layer tends to locate things like edges, curves or corners. Then it passes through another layer which finds more complex features that edges, curves or corners build like circles, squares etc.

After you did the convolution you will wind up with a new condensed version of your image. then you tend to do a pooling.

In general, what a Convnet is doing is drastically simplifying your image and looking for features.

### Dataset
Ibn this tutorial we are using the ``Kaggle Cats and Dogs`` dataset.The dataset contains cats and dogs in different sizes, colors and with different backgrounds where dogs are not dominating the photo. Download the dataset, unzip it and add to the directory.

### Preparing the dataset
*Note*: `os` module already comes with Python but if you don't have any of the `cv2` or `tqdm` open a terminal and pip install them.
"""

import os
import cv2 # Unofficial pre-built CPU-only OpenCV packages for Python
import numpy as np
from tqdm import tqdm # library used for creating Progress Meters or Progress Bars.

"""Generally, the pre-processing step can take a pretty long time  and it is better to run it as few times as you have to. Often it would be the case that you seperate your pre-processing from your neural network code. When there is not that much code to be written you use a flag.

Here we will make a flag called `REBUILD_DATA` and set it to be `True`.

"""

REBUILD_DATA = True

"""## Addin the Dataset
First you need to add it to your google drive. I downloaded the dataset on local computer, unzipped it and then just zipped the `PetImages`. Uploaded the `PetImages.zip` to the google drive and then unzipped it here. 
 - Note: Pay attention to the path you are giving. I was receiving errors due to the path incompatibilities. To find the right path use `! ls` and use the exact path for your `.zip` file.
"""

!unzip drive/MyDrive/Colab\ Notebooks/PetImages

"""### Data Processing Class

It is not necessary to have classes here, but in image processing you are going to do same methods every single time so it can be convenient to have classes.

- *IMG_SIZE*

  The IMG_SIZE is whatever we want, but we have to pick something. The images in the training data are all varying sizes and shapes. We're going to normalize all of the images by reshaping them to all be the same size. 
- *training_data*

  A list which is empty for now but will be populated with the images of cats and their labels also dogs and their labels.
- *Counters*

  Using counters and counting again is good in sense of being weary of balance.

We want to iterate through these two directories, grab the images, resize, scale, convert the class to number (cats = 0, dogs = 1), and add them to our training_data.



- *make_training_data*

  First we iterate over directories and then iterate over the images in the directories. Get the full path to the image and also convert it to the grayscale. 
  
  With Convnets we don't need to convert images into 1D inputs since we can have Convnets with any dimension (up to 4 has been implemented). Remember that adding color does not add to the dimension and it only adds channels, but its added data and we don't need. Take into consideration that color is not playing a role in classifying dogs and cats. 

üí°  The goal always is to simplify and make it as easy as possible for a neural network to learn. And also make a neural network as small as possible.


  - *os.listdir(path)*

    This method returns the list of files and directories in a given path.
  - *cv2.imread(path, flag)*

   A method that loads an image from the specified file.

   - path: A string representing the path of the image to be read.
   
   - flag: It specifies the way in which image should be read. It‚Äôs default value is cv2.IMREAD_COLOR

  - *self.training_data.append([np.array(img),np.eye(2)[self.LABELS[label]]])*

  Here we want to append the numpy array of the image as well as the class. However, since it is more clear if it is in one_hot vector form we are transforming the classes to on_hot vectors.
    - Converting Scalar Values to one_hot Vectors:
    
     We have got 2 classes here (cats=0, dogs=1). If we convert it to one_hot it should be [0 0] for no hots. For cats it should be [1 0], and for dogs it should be [0 1]. The `np.eye()`, which produces an identity matrix, is used for converting. We create an identity matrix of the size of our classes and each index represents the corresponding one_hot vector. In our case, there are 2 classes, `np.eye(2)` and for cats it would be `np.eye(2)[0]` which is equal to [1 0].


The goal for the cat/dog counts is to be identical or very close to eachother. If this is not the case we need to throw away some of the samples from the class with more samples. Otherwise, when your network is optimizing it will optimize for that specific class.

  - try/except

  Here try block is used because for whatever reason some of the images might not be good, and when you try to load them you will get an error (There is a corrupt or they are just empty) and we are handling it by passing it. 

  - *np.random.shuffle(self.training_data)*

  At this point, `training_data` would be a massive list of bunch of cats with cat label and bunch of dogs with dog labels. Now it will need to be shuffled.

"""

class DogsVSCats():
  IMG_SIZE = 50 
  CATS = "PetImages/Cat" #Image directories
  DOGS = "PetImages/Dog"
  LABELS = {CATS: 0, DOGS: 1}
  training_data = []
  catcount= 0 #counters
  dogcount= 0
  
  def make_training_data(self):
    for label in self.LABELS: # Iterate over cats and dogs (Over the keys of our dictionary)
      print(label) # Just to see the labels
      for f in tqdm(os.listdir(label)): # Iterate over the images withinn the directory
        try:
            path = os.path.join(label, f) # The full path to the image
            img = cv2.imread(path, cv2.IMREAD_GRAYSCALE) # Convert the images into gray scale
            img= cv2.resize(img, (self.IMG_SIZE, self.IMG_SIZE)) # Resizing the image
            self.training_data.append([np.array(img),np.eye(2)[self.LABELS[label]]])

            if label == self.CATS: #to check the balance
              self.catcount +=1
            elif label == self.DOGS:
              self.dogcount +=1
        except Exception as e:
            pass

    np.random.shuffle(self.training_data)
    np.save("training_data.npy", self.training_data) #save the shuffled list
    print("Cats:", self.catcount)
    print("Dogs:", self.dogcount)

if REBUILD_DATA:
  dogsvcats= DogsVSCats()
  dogsvcats.make_training_data()

"""Here we get our `ytraining_data` after saving it. We will do it only one time and never run again in this tutorial.

- *np.load("training_data.npy", allow_pickle=True)*

  Here we are loading pickled objects from .npy . ‚ÄúPickling‚Äù is the process whereby a Python object hierarchy is converted into a byte stream, and ‚Äúunpickling‚Äù is the inverse operation, whereby a byte stream (from a binary file or bytes-like object) is converted back into an object hierarchy.
  - allow_pickle

    Allow loading pickled object arrays stored in npy files. Reasons for disallowing pickles include security, as loading pickled data can execute arbitrary code. If pickles are disallowed, loading object arrays will fail. Default: False

- *plt.imshow(training_data[1][0], cmap="gray")*

  Display data as an image, i.e., on a 2D regular raster. The first element is the image data. It indicates the rowa and columns of the image. For the `training_data[1][0]` since the length of the `training_data` is 24946, you can replace [1] with 0-24945. But the [0] part has to remain the same. 

- *plt.show()*
Display all open figures.


"""

training_data = np.load("training_data.npy", allow_pickle=True)
print(len(training_data))
print(training_data[24945]) #an image and its label

# visualizing the image
import matplotlib.pyplot as plt
plt.imshow(training_data[24945][0], cmap="gray") #adding colormap to see the image better
plt.show()

"""## Splitting the data
Now we can split our data into x and y, as well as convert it to a tensor: 
"""

import torch

X = torch.Tensor([i[0] for i in training_data]).view(-1,50,50)
X = X/255.0
y = torch.Tensor([i[1] for i in training_data])

"""## Take a peak at one of our samples"""

import matplotlib.pyplot as plt

plt.imshow(X[0], cmap="gray")
print(y[0])